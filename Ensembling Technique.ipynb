{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a9b56fa-1a80-4ff7-a346-b9a0346864ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf3e5770-3ddf-469e-b5d0-5531fcd2e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "908a0108-1f8e-49c2-857e-5036512ea408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bank-full.csv',sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7302aad5-2625-457e-8032-33be4ec2bb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>51</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>72</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age           job   marital  education default  balance housing loan  \\\n",
       "45206   51    technician   married   tertiary      no      825      no   no   \n",
       "45207   71       retired  divorced    primary      no     1729      no   no   \n",
       "45208   72       retired   married  secondary      no     5715      no   no   \n",
       "45209   57   blue-collar   married  secondary      no      668      no   no   \n",
       "45210   37  entrepreneur   married  secondary      no     2971      no   no   \n",
       "\n",
       "         contact  day month  duration  campaign  pdays  previous poutcome    y  \n",
       "45206   cellular   17   nov       977         3     -1         0  unknown  yes  \n",
       "45207   cellular   17   nov       456         2     -1         0  unknown  yes  \n",
       "45208   cellular   17   nov      1127         5    184         3  success  yes  \n",
       "45209  telephone   17   nov       508         4     -1         0  unknown   no  \n",
       "45210   cellular   17   nov       361         2    188        11    other   no  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1b77f16-22db-43bb-b86f-b7fe11f63428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5ce7b0e-3ba5-468b-8b75-875b19fb716c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.936210</td>\n",
       "      <td>1362.272058</td>\n",
       "      <td>15.806419</td>\n",
       "      <td>258.163080</td>\n",
       "      <td>2.763841</td>\n",
       "      <td>40.197828</td>\n",
       "      <td>0.580323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.618762</td>\n",
       "      <td>3044.765829</td>\n",
       "      <td>8.322476</td>\n",
       "      <td>257.527812</td>\n",
       "      <td>3.098021</td>\n",
       "      <td>100.128746</td>\n",
       "      <td>2.303441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>102127.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>275.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        balance           day      duration      campaign  \\\n",
       "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
       "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
       "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
       "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
       "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
       "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
       "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
       "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
       "\n",
       "              pdays      previous  \n",
       "count  45211.000000  45211.000000  \n",
       "mean      40.197828      0.580323  \n",
       "std      100.128746      2.303441  \n",
       "min       -1.000000      0.000000  \n",
       "25%       -1.000000      0.000000  \n",
       "50%       -1.000000      0.000000  \n",
       "75%       -1.000000      0.000000  \n",
       "max      871.000000    275.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9438155a-2d5f-4681-9707-7a7dac18ff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "y            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3d8cbab-b3ea-4aa9-b703-07f9ad100701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   58    4        1          2        0     2143        1     0        2   \n",
       "1   44    9        2          1        0       29        1     0        2   \n",
       "2   33    2        1          1        0        2        1     1        2   \n",
       "3   47    1        1          3        0     1506        1     0        2   \n",
       "4   33   11        2          3        0        1        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  y  \n",
       "0    5      8       261         1     -1         0         3  0  \n",
       "1    5      8       151         1     -1         0         3  0  \n",
       "2    5      8        76         1     -1         0         3  0  \n",
       "3    5      8        92         1     -1         0         3  0  \n",
       "4    5      8       198         1     -1         0         3  0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "for i in df.select_dtypes('object').columns:\n",
    "    df[i] = le.fit_transform(df[i]) # doing this to change the object datatype into numerical datatype\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "438da400-5a32-4b02-82da-3e758b2a2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('y',axis=1)\n",
    "y=df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6991f80-dbe7-467c-95cc-3de88dfef515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.092259</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.053070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.073067</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.030704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.072822</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.015453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.376623</td>\n",
       "      <td>0.086476</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.018707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.040260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age   balance       day  duration\n",
       "0  0.519481  0.092259  0.133333  0.053070\n",
       "1  0.337662  0.073067  0.133333  0.030704\n",
       "2  0.194805  0.072822  0.133333  0.015453\n",
       "3  0.376623  0.086476  0.133333  0.018707\n",
       "4  0.194805  0.072812  0.133333  0.040260"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mms=MinMaxScaler()\n",
    "X[['age','balance','day','duration']] = mms.fit_transform(X[['age','balance','day','duration']])\n",
    "X[['age','balance','day','duration']].head() # balance,duration,age and day have wide ranges when compared to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "079639c2-bf64-4bb6-82ea-266b219416ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train: (33908, 16) \n",
      "X-Test: (11303, 16)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.25, random_state=0)\n",
    "print(\"X-Train:\",X_train.shape,\"\\nX-Test:\",X_test.shape) # train-test split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80569122-9ce9-48c9-9023-d8ceb102aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models used for ensembling\n",
    "\n",
    "#base models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'KNN_Bagging': BaggingClassifier(base_estimator=KNeighborsClassifier(), n_estimators=10, random_state=42),\n",
    "    'LogReg_Bagging': BaggingClassifier(base_estimator=LogisticRegression(solver='liblinear'), n_estimators=10, random_state=42),\n",
    "    'Stacking': StackingClassifier(classifiers=[\n",
    "        RandomForestClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        XGBClassifier()\n",
    "    ],\n",
    "    meta_classifier=LogisticRegression(solver='liblinear'),\n",
    "    use_probas=True, average_probas=False),\n",
    "    'Voting': VotingClassifier(estimators=[\n",
    "        ('RandomForest', RandomForestClassifier()),\n",
    "        ('GradientBoosting', GradientBoostingClassifier()),\n",
    "        ('AdaBoost', AdaBoostClassifier()),\n",
    "        ('XGBoost', XGBClassifier())\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dd662ca-994f-4ad0-854e-84692a192cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters list\n",
    "ranges = {\n",
    "    'RandomForest': {\n",
    "        'n_estimators': range(10, 201),\n",
    "        'max_depth': [None] + list(range(10, 31)),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 9),\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': range(10, 201),\n",
    "        'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 9)\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': range(10, 201),\n",
    "        'learning_rate': [0.01, 0.1, 0.2, 0.3]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': range(10, 201),\n",
    "        'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_child_weight': range(1, 9),\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    },\n",
    "    'KNN_Bagging': {\n",
    "        'base_estimator__n_neighbors': range(3, 21),\n",
    "        'base_estimator__weights': ['uniform', 'distance'],\n",
    "        'base_estimator__p': [1, 2],\n",
    "        'n_estimators': range(5, 16),\n",
    "        'max_samples': [0.8, 1.0],\n",
    "        'max_features': [0.8, 1.0]\n",
    "    },\n",
    "    'LogReg_Bagging': {\n",
    "        'base_estimator__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'base_estimator__penalty': ['l1', 'l2'],\n",
    "        'n_estimators': range(5, 16),\n",
    "        'max_samples': [0.8, 1.0],\n",
    "        'max_features': [0.8, 1.0]\n",
    "    },\n",
    "    'Stacking': {\n",
    "        'meta_classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'use_probas': [True],\n",
    "        'average_probas': [False]\n",
    "    },\n",
    "    'Voting': {\n",
    "        'voting': ['hard', 'soft']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c57b3adc-2485-4b36-a2a4-8038a118291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model In Use: RandomForest AUC_train: 0.9858306814496376 AUC_test: 0.9258052999618028 F1_train: 0.7741840635107322 F1_test: 0.5063636363636365\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model In Use: GradientBoosting AUC_train: 0.9528416633349626 AUC_test: 0.9279607967717658 F1_train: 0.6383103549427985 F1_test: 0.5321814254859611\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model In Use: AdaBoost AUC_train: 0.9146744036564183 AUC_test: 0.9038830332391639 F1_train: 0.43977310643977313 F1_test: 0.43499511241446726\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model In Use: XGBoost AUC_train: 0.9665671328491287 AUC_test: 0.929573136371716 F1_train: 0.6906022028322129 F1_test: 0.5423291792006877\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model In Use: KNN_Bagging AUC_train: 0.9999888035196814 AUC_test: 0.8552951587832855 F1_train: 0.9804577012085368 F1_test: 0.24600246002460024\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model In Use: LogReg_Bagging AUC_train: 0.8770931015392878 AUC_test: 0.8645304953917488 F1_train: 0.256041541841422 F1_test: 0.26081802015411976\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Model In Use: Stacking AUC_train: 0.999208167051419 AUC_test: 0.9313790716935748 F1_train: 0.8263508512213176 F1_test: 0.4087513340448239\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model In Use: Voting AUC_train: 0.9944650633419179 AUC_test: 0.930711187253467 F1_train: 0.8432570697740515 F1_test: 0.5197339246119734\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC_train</th>\n",
       "      <th>AUC_test</th>\n",
       "      <th>F1_train</th>\n",
       "      <th>F1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.985831</td>\n",
       "      <td>0.925805</td>\n",
       "      <td>0.774184</td>\n",
       "      <td>0.506364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.952842</td>\n",
       "      <td>0.927961</td>\n",
       "      <td>0.638310</td>\n",
       "      <td>0.532181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.914674</td>\n",
       "      <td>0.903883</td>\n",
       "      <td>0.439773</td>\n",
       "      <td>0.434995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.966567</td>\n",
       "      <td>0.929573</td>\n",
       "      <td>0.690602</td>\n",
       "      <td>0.542329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.855295</td>\n",
       "      <td>0.980458</td>\n",
       "      <td>0.246002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>0.877093</td>\n",
       "      <td>0.864530</td>\n",
       "      <td>0.256042</td>\n",
       "      <td>0.260818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>0.931379</td>\n",
       "      <td>0.826351</td>\n",
       "      <td>0.408751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.994465</td>\n",
       "      <td>0.930711</td>\n",
       "      <td>0.843257</td>\n",
       "      <td>0.519734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  AUC_train  AUC_test  F1_train   F1_test\n",
       "0      RandomForest   0.985831  0.925805  0.774184  0.506364\n",
       "1  GradientBoosting   0.952842  0.927961  0.638310  0.532181\n",
       "2          AdaBoost   0.914674  0.903883  0.439773  0.434995\n",
       "3           XGBoost   0.966567  0.929573  0.690602  0.542329\n",
       "4       KNN_Bagging   0.999989  0.855295  0.980458  0.246002\n",
       "5    LogReg_Bagging   0.877093  0.864530  0.256042  0.260818\n",
       "6          Stacking   0.999208  0.931379  0.826351  0.408751\n",
       "7            Voting   0.994465  0.930711  0.843257  0.519734"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "# Iterate over models\n",
    "for model_name, model in models.items():\n",
    "    # Initialize RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_distributions=ranges[model_name],\n",
    "        n_iter=10,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        cv=StratifiedKFold(n_splits=3),\n",
    "        random_state=0,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Perform RandomizedSearchCV on the training data\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = random_search.best_params_\n",
    "\n",
    "    # Create a new instance of the model with the best hyperparameters\n",
    "    best_model = model.set_params(**best_params)\n",
    "\n",
    "    # Fit the best model on the training data\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the training and test sets\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate AUC scores\n",
    "    auc_train = roc_auc_score(y_train, best_model.predict_proba(X_train)[:, 1])\n",
    "    auc_test = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    # Calculate F1 scores\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    print('Model In Use:', model_name,\n",
    "          'AUC_train:', auc_train, 'AUC_test:', auc_test,\n",
    "          'F1_train:', f1_train, 'F1_test:', f1_test)\n",
    "\n",
    "    results_list.append({\n",
    "        'Model': model_name,\n",
    "        'AUC_train': auc_train,\n",
    "        'AUC_test': auc_test,\n",
    "        'F1_train': f1_train,\n",
    "        'F1_test': f1_test\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02273d2a-55aa-4fb5-a29f-59bb9a3ed48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC_train</th>\n",
       "      <th>AUC_test</th>\n",
       "      <th>F1_train</th>\n",
       "      <th>F1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.985831</td>\n",
       "      <td>0.925805</td>\n",
       "      <td>0.774184</td>\n",
       "      <td>0.506364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.952842</td>\n",
       "      <td>0.927961</td>\n",
       "      <td>0.638310</td>\n",
       "      <td>0.532181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.914674</td>\n",
       "      <td>0.903883</td>\n",
       "      <td>0.439773</td>\n",
       "      <td>0.434995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.966567</td>\n",
       "      <td>0.929573</td>\n",
       "      <td>0.690602</td>\n",
       "      <td>0.542329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.855295</td>\n",
       "      <td>0.980458</td>\n",
       "      <td>0.246002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>0.877093</td>\n",
       "      <td>0.864530</td>\n",
       "      <td>0.256042</td>\n",
       "      <td>0.260818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>0.931379</td>\n",
       "      <td>0.826351</td>\n",
       "      <td>0.408751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Voting</td>\n",
       "      <td>0.994465</td>\n",
       "      <td>0.930711</td>\n",
       "      <td>0.843257</td>\n",
       "      <td>0.519734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  AUC_train  AUC_test  F1_train   F1_test\n",
       "0      RandomForest   0.985831  0.925805  0.774184  0.506364\n",
       "1  GradientBoosting   0.952842  0.927961  0.638310  0.532181\n",
       "2          AdaBoost   0.914674  0.903883  0.439773  0.434995\n",
       "3           XGBoost   0.966567  0.929573  0.690602  0.542329\n",
       "4       KNN_Bagging   0.999989  0.855295  0.980458  0.246002\n",
       "5    LogReg_Bagging   0.877093  0.864530  0.256042  0.260818\n",
       "6          Stacking   0.999208  0.931379  0.826351  0.408751\n",
       "7            Voting   0.994465  0.930711  0.843257  0.519734"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5fc41a6-b9a6-4063-a7f1-4bdbbc8e24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_techniques = {\n",
    "    'SMOTE': SMOTE(random_state=0),\n",
    "    'Random Oversampling': RandomOverSampler(random_state=0),\n",
    "    'Random Undersampling': RandomUnderSampler(random_state=0)\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'KNN_Bagging': BaggingClassifier(base_estimator=KNeighborsClassifier(), n_estimators=10, random_state=42),\n",
    "    'LogReg_Bagging': BaggingClassifier(base_estimator=LogisticRegression(solver='liblinear'), n_estimators=10, random_state=42),\n",
    "    'Stacking': StackingClassifier(classifiers=[\n",
    "        RandomForestClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        AdaBoostClassifier(),\n",
    "        XGBClassifier()\n",
    "    ],\n",
    "    meta_classifier=LogisticRegression(solver='liblinear'),\n",
    "    use_probas=True, average_probas=False),\n",
    "    'Voting': VotingClassifier(estimators=[\n",
    "        ('RandomForest', RandomForestClassifier()),\n",
    "        ('GradientBoosting', GradientBoostingClassifier()),\n",
    "        ('AdaBoost', AdaBoostClassifier()),\n",
    "        ('XGBoost', XGBClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "results_list2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a12edf0c-8391-4d63-b21c-a6693e6b3e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model RandomForest Sampling Technique SMOTE AUC_train 0.9999999732334984 AUC_test 0.9144920712359643 F1_train 0.9992158171352298 F1_test 0.578756621131865 Best_threshold 0.4 Model fitted with threshold RandomForestClassifier(bootstrap=False, max_depth=25, min_samples_split=3,\n",
      "                       n_estimators=65)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model GradientBoosting Sampling Technique SMOTE AUC_train 0.9991806718074291 AUC_test 0.9180284172348979 F1_train 0.9852347655666097 F1_test 0.5897291196388261 Best_threshold 0.3 Model fitted with threshold GradientBoostingClassifier(max_depth=10, min_samples_leaf=2,\n",
      "                           min_samples_split=7, n_estimators=94)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model AdaBoost Sampling Technique SMOTE AUC_train 0.9390765291042166 AUC_test 0.8852990541455352 F1_train 0.8740563250836999 F1_test 0.5254059717129388 Best_threshold 0.5 Model fitted with threshold AdaBoostClassifier(learning_rate=0.3, n_estimators=193)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model XGBoost Sampling Technique SMOTE AUC_train 0.9969948345202077 AUC_test 0.9233488769632816 F1_train 0.9706661336265054 F1_test 0.6009334889148191 Best_threshold 0.3 Model fitted with threshold XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=110, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model KNN_Bagging Sampling Technique SMOTE AUC_train 0.9999927663529228 AUC_test 0.8621595812674677 F1_train 0.9984487331320577 F1_test 0.5050816137973514 Best_threshold 0.5 Model fitted with threshold BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=10, p=1,\n",
      "                                                      weights='distance'),\n",
      "                  max_features=0.8, n_estimators=12, random_state=42)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model LogReg_Bagging Sampling Technique SMOTE AUC_train 0.9131234023075152 AUC_test 0.8567431746067765 F1_train 0.8491564834512443 F1_test 0.4961288324558687 Best_threshold 0.6 Model fitted with threshold BaggingClassifier(base_estimator=LogisticRegression(C=10, solver='liblinear'),\n",
      "                  max_features=0.8, n_estimators=15, random_state=42)\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Model Stacking Sampling Technique SMOTE AUC_train 0.9996970032010594 AUC_test 0.9213918923518534 F1_train 0.9892963561000783 F1_test 0.5979628520071899 Best_threshold 0.4 Model fitted with threshold StackingClassifier(classifiers=[RandomForestClassifier(),\n",
      "                                GradientBoostingClassifier(),\n",
      "                                AdaBoostClassifier(),\n",
      "                                XGBClassifier(base_score=None, booster=None,\n",
      "                                              callbacks=None,\n",
      "                                              colsample_bylevel=None,\n",
      "                                              colsample_bynode=None,\n",
      "                                              colsample_bytree=None,\n",
      "                                              device=None,\n",
      "                                              early_stopping_rounds=None,\n",
      "                                              enable_categorical=False,\n",
      "                                              eval_metric=None,\n",
      "                                              feature_types=None, gamma=None,\n",
      "                                              grow_po...\n",
      "                                              learning_rate=None, max_bin=None,\n",
      "                                              max_cat_threshold=None,\n",
      "                                              max_cat_to_onehot=None,\n",
      "                                              max_delta_step=None,\n",
      "                                              max_depth=None, max_leaves=None,\n",
      "                                              min_child_weight=None,\n",
      "                                              missing=nan,\n",
      "                                              monotone_constraints=None,\n",
      "                                              multi_strategy=None,\n",
      "                                              n_estimators=None, n_jobs=None,\n",
      "                                              num_parallel_tree=None,\n",
      "                                              random_state=None, ...)],\n",
      "                   meta_classifier=LogisticRegression(C=0.001,\n",
      "                                                      solver='liblinear'),\n",
      "                   use_probas=True)\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model Voting Sampling Technique SMOTE AUC_train 0.9981315197398667 AUC_test 0.9188493931933273 F1_train 0.9713494900901197 F1_test 0.5960183767228179 Best_threshold 0.5 Model fitted with threshold VotingClassifier(estimators=[('RandomForest', RandomForestClassifier()),\n",
      "                             ('GradientBoosting', GradientBoostingClassifier()),\n",
      "                             ('AdaBoost', AdaBoostClassifier()),\n",
      "                             ('XGBoost',\n",
      "                              XGBClassifier(base_score=None, booster=None,\n",
      "                                            callbacks=None,\n",
      "                                            colsample_bylevel=None,\n",
      "                                            colsample_bynode=None,\n",
      "                                            colsample_bytree=None, device=None,\n",
      "                                            early_stopping_rounds=None,\n",
      "                                            enable_categorical=F...\n",
      "                                            importance_type=None,\n",
      "                                            interaction_constraints=None,\n",
      "                                            learning_rate=None, max_bin=None,\n",
      "                                            max_cat_threshold=None,\n",
      "                                            max_cat_to_onehot=None,\n",
      "                                            max_delta_step=None, max_depth=None,\n",
      "                                            max_leaves=None,\n",
      "                                            min_child_weight=None, missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            multi_strategy=None,\n",
      "                                            n_estimators=None, n_jobs=None,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            random_state=None, ...))],\n",
      "                 voting='soft')\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model RandomForest Sampling Technique Random Oversampling AUC_train 1.0 AUC_test 0.9180128736049498 F1_train 0.9999833024428526 F1_test 0.590982808952319 Best_threshold 0.3 Model fitted with threshold RandomForestClassifier(bootstrap=False, max_depth=25, min_samples_split=3,\n",
      "                       n_estimators=65)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model GradientBoosting Sampling Technique Random Oversampling AUC_train 0.9988583417873842 AUC_test 0.9222798080304973 F1_train 0.9819215724944943 F1_test 0.6000000000000001 Best_threshold 0.5 Model fitted with threshold GradientBoostingClassifier(max_depth=10, min_samples_leaf=2,\n",
      "                           min_samples_split=7, n_estimators=94)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model AdaBoost Sampling Technique Random Oversampling AUC_train 0.9152417980479582 AUC_test 0.9054720006656153 F1_train 0.8405002340667425 F1_test 0.545320197044335 Best_threshold 0.5 Model fitted with threshold AdaBoostClassifier(learning_rate=0.3, n_estimators=193)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model XGBoost Sampling Technique Random Oversampling AUC_train 0.9938334586213797 AUC_test 0.9215741801775227 F1_train 0.965604722642338 F1_test 0.6026825633383011 Best_threshold 0.5 Model fitted with threshold XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=110, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model KNN_Bagging Sampling Technique Random Oversampling AUC_train 0.9999983616670436 AUC_test 0.8551599178570213 F1_train 0.9989990991892703 F1_test 0.4945158257599499 Best_threshold 0.5 Model fitted with threshold BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=10, p=1,\n",
      "                                                      weights='distance'),\n",
      "                  max_features=0.8, n_estimators=12, random_state=42)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model LogReg_Bagging Sampling Technique Random Oversampling AUC_train 0.8781222923453016 AUC_test 0.8670514376912226 F1_train 0.8068705488060326 F1_test 0.5081476554705686 Best_threshold 0.7 Model fitted with threshold BaggingClassifier(base_estimator=LogisticRegression(C=100, solver='liblinear'),\n",
      "                  n_estimators=15, random_state=42)\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Model Stacking Sampling Technique Random Oversampling AUC_train 0.9999985802601404 AUC_test 0.9284078557732672 F1_train 0.9955613186374744 F1_test 0.6125347329422661 Best_threshold 0.4 Model fitted with threshold StackingClassifier(classifiers=[RandomForestClassifier(),\n",
      "                                GradientBoostingClassifier(),\n",
      "                                AdaBoostClassifier(),\n",
      "                                XGBClassifier(base_score=None, booster=None,\n",
      "                                              callbacks=None,\n",
      "                                              colsample_bylevel=None,\n",
      "                                              colsample_bynode=None,\n",
      "                                              colsample_bytree=None,\n",
      "                                              device=None,\n",
      "                                              early_stopping_rounds=None,\n",
      "                                              enable_categorical=False,\n",
      "                                              eval_metric=None,\n",
      "                                              feature_types=None, gamma=None,\n",
      "                                              grow_po...\n",
      "                                              learning_rate=None, max_bin=None,\n",
      "                                              max_cat_threshold=None,\n",
      "                                              max_cat_to_onehot=None,\n",
      "                                              max_delta_step=None,\n",
      "                                              max_depth=None, max_leaves=None,\n",
      "                                              min_child_weight=None,\n",
      "                                              missing=nan,\n",
      "                                              monotone_constraints=None,\n",
      "                                              multi_strategy=None,\n",
      "                                              n_estimators=None, n_jobs=None,\n",
      "                                              num_parallel_tree=None,\n",
      "                                              random_state=None, ...)],\n",
      "                   meta_classifier=LogisticRegression(C=0.001,\n",
      "                                                      solver='liblinear'),\n",
      "                   use_probas=True)\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model Voting Sampling Technique Random Oversampling AUC_train 0.9984967475399265 AUC_test 0.9284556590536917 F1_train 0.9699956091135289 F1_test 0.6107402031930333 Best_threshold 0.5 Model fitted with threshold VotingClassifier(estimators=[('RandomForest', RandomForestClassifier()),\n",
      "                             ('GradientBoosting', GradientBoostingClassifier()),\n",
      "                             ('AdaBoost', AdaBoostClassifier()),\n",
      "                             ('XGBoost',\n",
      "                              XGBClassifier(base_score=None, booster=None,\n",
      "                                            callbacks=None,\n",
      "                                            colsample_bylevel=None,\n",
      "                                            colsample_bynode=None,\n",
      "                                            colsample_bytree=None, device=None,\n",
      "                                            early_stopping_rounds=None,\n",
      "                                            enable_categorical=F...\n",
      "                                            importance_type=None,\n",
      "                                            interaction_constraints=None,\n",
      "                                            learning_rate=None, max_bin=None,\n",
      "                                            max_cat_threshold=None,\n",
      "                                            max_cat_to_onehot=None,\n",
      "                                            max_delta_step=None, max_depth=None,\n",
      "                                            max_leaves=None,\n",
      "                                            min_child_weight=None, missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            multi_strategy=None,\n",
      "                                            n_estimators=None, n_jobs=None,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            random_state=None, ...))],\n",
      "                 voting='soft')\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model RandomForest Sampling Technique Random Undersampling AUC_train 0.976399731794017 AUC_test 0.9141848670849454 F1_train 0.9086887059112695 F1_test 0.5791388720436629 Best_threshold 0.7 Model fitted with threshold RandomForestClassifier(max_depth=13, min_samples_leaf=2, min_samples_split=13,\n",
      "                       n_estimators=110)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model GradientBoosting Sampling Technique Random Undersampling AUC_train 0.9681267380185544 AUC_test 0.9258813918923519 F1_train 0.9073363850055671 F1_test 0.6039719626168224 Best_threshold 0.7 Model fitted with threshold GradientBoostingClassifier(learning_rate=0.2, min_samples_leaf=8,\n",
      "                           min_samples_split=9, n_estimators=192)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model AdaBoost Sampling Technique Random Undersampling AUC_train 0.9161827028524124 AUC_test 0.9048412545335588 F1_train 0.8440575321725965 F1_test 0.5398381956361854 Best_threshold 0.5 Model fitted with threshold AdaBoostClassifier(learning_rate=0.3, n_estimators=193)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model XGBoost Sampling Technique Random Undersampling AUC_train 0.951247879502811 AUC_test 0.9225658713320246 F1_train 0.8879811857903205 F1_test 0.5969884853852966 Best_threshold 0.7 Model fitted with threshold XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=2, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=80, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model KNN_Bagging Sampling Technique Random Undersampling AUC_train 0.9997792315501471 AUC_test 0.8313785422268615 F1_train 0.994576869718754 F1_test 0.4709459459459459 Best_threshold 0.6 Model fitted with threshold BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=12, p=1,\n",
      "                                                      weights='distance'),\n",
      "                  max_features=0.8, max_samples=0.8, n_estimators=15,\n",
      "                  random_state=42)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Model LogReg_Bagging Sampling Technique Random Undersampling AUC_train 0.8805906793838797 AUC_test 0.8676749225654932 F1_train 0.8052604957005562 F1_test 0.5056179775280899 Best_threshold 0.7 Model fitted with threshold BaggingClassifier(base_estimator=LogisticRegression(C=10, penalty='l1',\n",
      "                                                    solver='liblinear'),\n",
      "                  n_estimators=15, random_state=42)\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Model Stacking Sampling Technique Random Undersampling AUC_train 0.9992253057538024 AUC_test 0.925301777117205 F1_train 0.9818908455101786 F1_test 0.5959757266049185 Best_threshold 0.7 Model fitted with threshold StackingClassifier(classifiers=[RandomForestClassifier(),\n",
      "                                GradientBoostingClassifier(),\n",
      "                                AdaBoostClassifier(),\n",
      "                                XGBClassifier(base_score=None, booster=None,\n",
      "                                              callbacks=None,\n",
      "                                              colsample_bylevel=None,\n",
      "                                              colsample_bynode=None,\n",
      "                                              colsample_bytree=None,\n",
      "                                              device=None,\n",
      "                                              early_stopping_rounds=None,\n",
      "                                              enable_categorical=False,\n",
      "                                              eval_metric=None,\n",
      "                                              feature_types=None, gamma=None,\n",
      "                                              grow_po...\n",
      "                                              learning_rate=None, max_bin=None,\n",
      "                                              max_cat_threshold=None,\n",
      "                                              max_cat_to_onehot=None,\n",
      "                                              max_delta_step=None,\n",
      "                                              max_depth=None, max_leaves=None,\n",
      "                                              min_child_weight=None,\n",
      "                                              missing=nan,\n",
      "                                              monotone_constraints=None,\n",
      "                                              multi_strategy=None,\n",
      "                                              n_estimators=None, n_jobs=None,\n",
      "                                              num_parallel_tree=None,\n",
      "                                              random_state=None, ...)],\n",
      "                   meta_classifier=LogisticRegression(C=0.001,\n",
      "                                                      solver='liblinear'),\n",
      "                   use_probas=True)\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Model Voting Sampling Technique Random Undersampling AUC_train 0.9975317718192287 AUC_test 0.9247419795247658 F1_train 0.9680705677723941 F1_test 0.5912930474333983 Best_threshold 0.7 Model fitted with threshold VotingClassifier(estimators=[('RandomForest', RandomForestClassifier()),\n",
      "                             ('GradientBoosting', GradientBoostingClassifier()),\n",
      "                             ('AdaBoost', AdaBoostClassifier()),\n",
      "                             ('XGBoost',\n",
      "                              XGBClassifier(base_score=None, booster=None,\n",
      "                                            callbacks=None,\n",
      "                                            colsample_bylevel=None,\n",
      "                                            colsample_bynode=None,\n",
      "                                            colsample_bytree=None, device=None,\n",
      "                                            early_stopping_rounds=None,\n",
      "                                            enable_categorical=F...\n",
      "                                            importance_type=None,\n",
      "                                            interaction_constraints=None,\n",
      "                                            learning_rate=None, max_bin=None,\n",
      "                                            max_cat_threshold=None,\n",
      "                                            max_cat_to_onehot=None,\n",
      "                                            max_delta_step=None, max_depth=None,\n",
      "                                            max_leaves=None,\n",
      "                                            min_child_weight=None, missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            multi_strategy=None,\n",
      "                                            n_estimators=None, n_jobs=None,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            random_state=None, ...))],\n",
      "                 voting='soft')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sampling Technique</th>\n",
       "      <th>AUC_train</th>\n",
       "      <th>AUC_test</th>\n",
       "      <th>F1_train</th>\n",
       "      <th>F1_test</th>\n",
       "      <th>Best_threshold</th>\n",
       "      <th>Model_fitted_with_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914492</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.578757</td>\n",
       "      <td>0.4</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=13, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.999181</td>\n",
       "      <td>0.918028</td>\n",
       "      <td>0.985235</td>\n",
       "      <td>0.589729</td>\n",
       "      <td>0.3</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.939077</td>\n",
       "      <td>0.885299</td>\n",
       "      <td>0.874056</td>\n",
       "      <td>0.525406</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.996995</td>\n",
       "      <td>0.923349</td>\n",
       "      <td>0.970666</td>\n",
       "      <td>0.600933</td>\n",
       "      <td>0.3</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.862160</td>\n",
       "      <td>0.998449</td>\n",
       "      <td>0.505082</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(KNeighborsClassifier(n_neighbors=12, p=1, wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.913123</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.849156</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>0.6</td>\n",
       "      <td>(LogisticRegression(C=10, penalty='l1', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.999697</td>\n",
       "      <td>0.921392</td>\n",
       "      <td>0.989296</td>\n",
       "      <td>0.597963</td>\n",
       "      <td>0.4</td>\n",
       "      <td>StackingClassifier(classifiers=[RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Voting</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.998132</td>\n",
       "      <td>0.918849</td>\n",
       "      <td>0.971349</td>\n",
       "      <td>0.596018</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VotingClassifier(estimators=[('RandomForest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918013</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.590983</td>\n",
       "      <td>0.3</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=13, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.998858</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.981922</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.915242</td>\n",
       "      <td>0.905472</td>\n",
       "      <td>0.840500</td>\n",
       "      <td>0.545320</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.993833</td>\n",
       "      <td>0.921574</td>\n",
       "      <td>0.965605</td>\n",
       "      <td>0.602683</td>\n",
       "      <td>0.5</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.855160</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(KNeighborsClassifier(n_neighbors=12, p=1, wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.878122</td>\n",
       "      <td>0.867051</td>\n",
       "      <td>0.806871</td>\n",
       "      <td>0.508148</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(LogisticRegression(C=10, penalty='l1', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.928408</td>\n",
       "      <td>0.995561</td>\n",
       "      <td>0.612535</td>\n",
       "      <td>0.4</td>\n",
       "      <td>StackingClassifier(classifiers=[RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Voting</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>0.928456</td>\n",
       "      <td>0.969996</td>\n",
       "      <td>0.610740</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VotingClassifier(estimators=[('RandomForest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.976400</td>\n",
       "      <td>0.914185</td>\n",
       "      <td>0.908689</td>\n",
       "      <td>0.579139</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=13, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.968127</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>0.907336</td>\n",
       "      <td>0.603972</td>\n",
       "      <td>0.7</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.916183</td>\n",
       "      <td>0.904841</td>\n",
       "      <td>0.844058</td>\n",
       "      <td>0.539838</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.951248</td>\n",
       "      <td>0.922566</td>\n",
       "      <td>0.887981</td>\n",
       "      <td>0.596988</td>\n",
       "      <td>0.7</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.831379</td>\n",
       "      <td>0.994577</td>\n",
       "      <td>0.470946</td>\n",
       "      <td>0.6</td>\n",
       "      <td>(KNeighborsClassifier(n_neighbors=12, p=1, wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.880591</td>\n",
       "      <td>0.867675</td>\n",
       "      <td>0.805260</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(LogisticRegression(C=10, penalty='l1', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.925302</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.595976</td>\n",
       "      <td>0.7</td>\n",
       "      <td>StackingClassifier(classifiers=[RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Voting</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.997532</td>\n",
       "      <td>0.924742</td>\n",
       "      <td>0.968071</td>\n",
       "      <td>0.591293</td>\n",
       "      <td>0.7</td>\n",
       "      <td>VotingClassifier(estimators=[('RandomForest', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model    Sampling Technique  AUC_train  AUC_test  F1_train  \\\n",
       "0       RandomForest                 SMOTE   1.000000  0.914492  0.999216   \n",
       "1   GradientBoosting                 SMOTE   0.999181  0.918028  0.985235   \n",
       "2           AdaBoost                 SMOTE   0.939077  0.885299  0.874056   \n",
       "3            XGBoost                 SMOTE   0.996995  0.923349  0.970666   \n",
       "4        KNN_Bagging                 SMOTE   0.999993  0.862160  0.998449   \n",
       "5     LogReg_Bagging                 SMOTE   0.913123  0.856743  0.849156   \n",
       "6           Stacking                 SMOTE   0.999697  0.921392  0.989296   \n",
       "7             Voting                 SMOTE   0.998132  0.918849  0.971349   \n",
       "8       RandomForest   Random Oversampling   1.000000  0.918013  0.999983   \n",
       "9   GradientBoosting   Random Oversampling   0.998858  0.922280  0.981922   \n",
       "10          AdaBoost   Random Oversampling   0.915242  0.905472  0.840500   \n",
       "11           XGBoost   Random Oversampling   0.993833  0.921574  0.965605   \n",
       "12       KNN_Bagging   Random Oversampling   0.999998  0.855160  0.998999   \n",
       "13    LogReg_Bagging   Random Oversampling   0.878122  0.867051  0.806871   \n",
       "14          Stacking   Random Oversampling   0.999999  0.928408  0.995561   \n",
       "15            Voting   Random Oversampling   0.998497  0.928456  0.969996   \n",
       "16      RandomForest  Random Undersampling   0.976400  0.914185  0.908689   \n",
       "17  GradientBoosting  Random Undersampling   0.968127  0.925881  0.907336   \n",
       "18          AdaBoost  Random Undersampling   0.916183  0.904841  0.844058   \n",
       "19           XGBoost  Random Undersampling   0.951248  0.922566  0.887981   \n",
       "20       KNN_Bagging  Random Undersampling   0.999779  0.831379  0.994577   \n",
       "21    LogReg_Bagging  Random Undersampling   0.880591  0.867675  0.805260   \n",
       "22          Stacking  Random Undersampling   0.999225  0.925302  0.981891   \n",
       "23            Voting  Random Undersampling   0.997532  0.924742  0.968071   \n",
       "\n",
       "     F1_test  Best_threshold  \\\n",
       "0   0.578757             0.4   \n",
       "1   0.589729             0.3   \n",
       "2   0.525406             0.5   \n",
       "3   0.600933             0.3   \n",
       "4   0.505082             0.5   \n",
       "5   0.496129             0.6   \n",
       "6   0.597963             0.4   \n",
       "7   0.596018             0.5   \n",
       "8   0.590983             0.3   \n",
       "9   0.600000             0.5   \n",
       "10  0.545320             0.5   \n",
       "11  0.602683             0.5   \n",
       "12  0.494516             0.5   \n",
       "13  0.508148             0.7   \n",
       "14  0.612535             0.4   \n",
       "15  0.610740             0.5   \n",
       "16  0.579139             0.7   \n",
       "17  0.603972             0.7   \n",
       "18  0.539838             0.5   \n",
       "19  0.596988             0.7   \n",
       "20  0.470946             0.6   \n",
       "21  0.505618             0.7   \n",
       "22  0.595976             0.7   \n",
       "23  0.591293             0.7   \n",
       "\n",
       "                          Model_fitted_with_threshold  \n",
       "0   (DecisionTreeClassifier(max_depth=13, max_feat...  \n",
       "1   ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "2   (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "3   XGBClassifier(base_score=None, booster=None, c...  \n",
       "4   (KNeighborsClassifier(n_neighbors=12, p=1, wei...  \n",
       "5   (LogisticRegression(C=10, penalty='l1', random...  \n",
       "6   StackingClassifier(classifiers=[RandomForestCl...  \n",
       "7   VotingClassifier(estimators=[('RandomForest', ...  \n",
       "8   (DecisionTreeClassifier(max_depth=13, max_feat...  \n",
       "9   ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "10  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "11  XGBClassifier(base_score=None, booster=None, c...  \n",
       "12  (KNeighborsClassifier(n_neighbors=12, p=1, wei...  \n",
       "13  (LogisticRegression(C=10, penalty='l1', random...  \n",
       "14  StackingClassifier(classifiers=[RandomForestCl...  \n",
       "15  VotingClassifier(estimators=[('RandomForest', ...  \n",
       "16  (DecisionTreeClassifier(max_depth=13, max_feat...  \n",
       "17  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "18  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "19  XGBClassifier(base_score=None, booster=None, c...  \n",
       "20  (KNeighborsClassifier(n_neighbors=12, p=1, wei...  \n",
       "21  (LogisticRegression(C=10, penalty='l1', random...  \n",
       "22  StackingClassifier(classifiers=[RandomForestCl...  \n",
       "23  VotingClassifier(estimators=[('RandomForest', ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sampling_name, sampling_technique in sampling_techniques.items():\n",
    "    X_train_res, y_train_res = X_train, y_train  \n",
    "    \n",
    "    if sampling_technique:\n",
    "        X_train_res, y_train_res = sampling_technique.fit_resample(X_train, y_train)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        random_search = RandomizedSearchCV(model, param_distributions=ranges[model_name],\n",
    "                                           n_iter=10, scoring='roc_auc', n_jobs=-1, cv=StratifiedKFold(n_splits=3),\n",
    "                                           random_state=42, verbose=2)\n",
    "\n",
    "        random_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "        best_model = model.set_params(**random_search.best_params_)\n",
    "        best_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "        y_train_pred = best_model.predict(X_train_res)\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "        auc_train = roc_auc_score(y_train_res, best_model.predict_proba(X_train_res)[:, 1])\n",
    "        auc_test = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "        f1_train = f1_score(y_train_res, y_train_pred)\n",
    "\n",
    "        y_test_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "        thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "        best_threshold = 0\n",
    "        best_f1_score_test = 0\n",
    "        for threshold in thresholds:\n",
    "            y_test_pred_adjusted = (y_test_probs > threshold).astype(int)\n",
    "            f1_test_adjusted = f1_score(y_test, y_test_pred_adjusted)\n",
    "            if f1_test_adjusted > best_f1_score_test:\n",
    "                best_f1_score_test = f1_test_adjusted\n",
    "                best_threshold = threshold\n",
    "\n",
    "        f1_test = best_f1_score_test\n",
    "\n",
    "        print('Model',model_name, 'Sampling Technique', sampling_name,\n",
    "                                'AUC_train',auc_train, 'AUC_test', auc_test,\n",
    "                                'F1_train', f1_train, 'F1_test', f1_test, 'Best_threshold', best_threshold,\n",
    "                                'Model fitted with threshold', best_model)\n",
    "\n",
    "        results_list2.append({\n",
    "            'Model': model_name,\n",
    "            'Sampling Technique': sampling_name,\n",
    "            'AUC_train': auc_train,\n",
    "            'AUC_test': auc_test,\n",
    "            'F1_train': f1_train,\n",
    "            'F1_test': f1_test,\n",
    "            'Best_threshold': best_threshold,\n",
    "            'Model_fitted_with_threshold': best_model\n",
    "        })\n",
    "        \n",
    "results_df2 = pd.DataFrame(results_list2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c983d583-ecdc-47f8-8e02-c8fa5030a49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sampling Technique</th>\n",
       "      <th>AUC_train</th>\n",
       "      <th>AUC_test</th>\n",
       "      <th>F1_train</th>\n",
       "      <th>F1_test</th>\n",
       "      <th>Best_threshold</th>\n",
       "      <th>Model_fitted_with_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914492</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.578757</td>\n",
       "      <td>0.4</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=13, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.999181</td>\n",
       "      <td>0.918028</td>\n",
       "      <td>0.985235</td>\n",
       "      <td>0.589729</td>\n",
       "      <td>0.3</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.939077</td>\n",
       "      <td>0.885299</td>\n",
       "      <td>0.874056</td>\n",
       "      <td>0.525406</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.996995</td>\n",
       "      <td>0.923349</td>\n",
       "      <td>0.970666</td>\n",
       "      <td>0.600933</td>\n",
       "      <td>0.3</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.862160</td>\n",
       "      <td>0.998449</td>\n",
       "      <td>0.505082</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(KNeighborsClassifier(n_neighbors=12, p=1, wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.913123</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.849156</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>0.6</td>\n",
       "      <td>(LogisticRegression(C=10, penalty='l1', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.999697</td>\n",
       "      <td>0.921392</td>\n",
       "      <td>0.989296</td>\n",
       "      <td>0.597963</td>\n",
       "      <td>0.4</td>\n",
       "      <td>StackingClassifier(classifiers=[RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Voting</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.998132</td>\n",
       "      <td>0.918849</td>\n",
       "      <td>0.971349</td>\n",
       "      <td>0.596018</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VotingClassifier(estimators=[('RandomForest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918013</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.590983</td>\n",
       "      <td>0.3</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=13, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.998858</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.981922</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.915242</td>\n",
       "      <td>0.905472</td>\n",
       "      <td>0.840500</td>\n",
       "      <td>0.545320</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.993833</td>\n",
       "      <td>0.921574</td>\n",
       "      <td>0.965605</td>\n",
       "      <td>0.602683</td>\n",
       "      <td>0.5</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.855160</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(KNeighborsClassifier(n_neighbors=12, p=1, wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.878122</td>\n",
       "      <td>0.867051</td>\n",
       "      <td>0.806871</td>\n",
       "      <td>0.508148</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(LogisticRegression(C=10, penalty='l1', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.928408</td>\n",
       "      <td>0.995561</td>\n",
       "      <td>0.612535</td>\n",
       "      <td>0.4</td>\n",
       "      <td>StackingClassifier(classifiers=[RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Voting</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>0.928456</td>\n",
       "      <td>0.969996</td>\n",
       "      <td>0.610740</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VotingClassifier(estimators=[('RandomForest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.976400</td>\n",
       "      <td>0.914185</td>\n",
       "      <td>0.908689</td>\n",
       "      <td>0.579139</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=13, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.968127</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>0.907336</td>\n",
       "      <td>0.603972</td>\n",
       "      <td>0.7</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.916183</td>\n",
       "      <td>0.904841</td>\n",
       "      <td>0.844058</td>\n",
       "      <td>0.539838</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.951248</td>\n",
       "      <td>0.922566</td>\n",
       "      <td>0.887981</td>\n",
       "      <td>0.596988</td>\n",
       "      <td>0.7</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.831379</td>\n",
       "      <td>0.994577</td>\n",
       "      <td>0.470946</td>\n",
       "      <td>0.6</td>\n",
       "      <td>(KNeighborsClassifier(n_neighbors=12, p=1, wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.880591</td>\n",
       "      <td>0.867675</td>\n",
       "      <td>0.805260</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(LogisticRegression(C=10, penalty='l1', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.925302</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.595976</td>\n",
       "      <td>0.7</td>\n",
       "      <td>StackingClassifier(classifiers=[RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Voting</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.997532</td>\n",
       "      <td>0.924742</td>\n",
       "      <td>0.968071</td>\n",
       "      <td>0.591293</td>\n",
       "      <td>0.7</td>\n",
       "      <td>VotingClassifier(estimators=[('RandomForest', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model    Sampling Technique  AUC_train  AUC_test  F1_train  \\\n",
       "0       RandomForest                 SMOTE   1.000000  0.914492  0.999216   \n",
       "1   GradientBoosting                 SMOTE   0.999181  0.918028  0.985235   \n",
       "2           AdaBoost                 SMOTE   0.939077  0.885299  0.874056   \n",
       "3            XGBoost                 SMOTE   0.996995  0.923349  0.970666   \n",
       "4        KNN_Bagging                 SMOTE   0.999993  0.862160  0.998449   \n",
       "5     LogReg_Bagging                 SMOTE   0.913123  0.856743  0.849156   \n",
       "6           Stacking                 SMOTE   0.999697  0.921392  0.989296   \n",
       "7             Voting                 SMOTE   0.998132  0.918849  0.971349   \n",
       "8       RandomForest   Random Oversampling   1.000000  0.918013  0.999983   \n",
       "9   GradientBoosting   Random Oversampling   0.998858  0.922280  0.981922   \n",
       "10          AdaBoost   Random Oversampling   0.915242  0.905472  0.840500   \n",
       "11           XGBoost   Random Oversampling   0.993833  0.921574  0.965605   \n",
       "12       KNN_Bagging   Random Oversampling   0.999998  0.855160  0.998999   \n",
       "13    LogReg_Bagging   Random Oversampling   0.878122  0.867051  0.806871   \n",
       "14          Stacking   Random Oversampling   0.999999  0.928408  0.995561   \n",
       "15            Voting   Random Oversampling   0.998497  0.928456  0.969996   \n",
       "16      RandomForest  Random Undersampling   0.976400  0.914185  0.908689   \n",
       "17  GradientBoosting  Random Undersampling   0.968127  0.925881  0.907336   \n",
       "18          AdaBoost  Random Undersampling   0.916183  0.904841  0.844058   \n",
       "19           XGBoost  Random Undersampling   0.951248  0.922566  0.887981   \n",
       "20       KNN_Bagging  Random Undersampling   0.999779  0.831379  0.994577   \n",
       "21    LogReg_Bagging  Random Undersampling   0.880591  0.867675  0.805260   \n",
       "22          Stacking  Random Undersampling   0.999225  0.925302  0.981891   \n",
       "23            Voting  Random Undersampling   0.997532  0.924742  0.968071   \n",
       "\n",
       "     F1_test  Best_threshold  \\\n",
       "0   0.578757             0.4   \n",
       "1   0.589729             0.3   \n",
       "2   0.525406             0.5   \n",
       "3   0.600933             0.3   \n",
       "4   0.505082             0.5   \n",
       "5   0.496129             0.6   \n",
       "6   0.597963             0.4   \n",
       "7   0.596018             0.5   \n",
       "8   0.590983             0.3   \n",
       "9   0.600000             0.5   \n",
       "10  0.545320             0.5   \n",
       "11  0.602683             0.5   \n",
       "12  0.494516             0.5   \n",
       "13  0.508148             0.7   \n",
       "14  0.612535             0.4   \n",
       "15  0.610740             0.5   \n",
       "16  0.579139             0.7   \n",
       "17  0.603972             0.7   \n",
       "18  0.539838             0.5   \n",
       "19  0.596988             0.7   \n",
       "20  0.470946             0.6   \n",
       "21  0.505618             0.7   \n",
       "22  0.595976             0.7   \n",
       "23  0.591293             0.7   \n",
       "\n",
       "                          Model_fitted_with_threshold  \n",
       "0   (DecisionTreeClassifier(max_depth=13, max_feat...  \n",
       "1   ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "2   (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "3   XGBClassifier(base_score=None, booster=None, c...  \n",
       "4   (KNeighborsClassifier(n_neighbors=12, p=1, wei...  \n",
       "5   (LogisticRegression(C=10, penalty='l1', random...  \n",
       "6   StackingClassifier(classifiers=[RandomForestCl...  \n",
       "7   VotingClassifier(estimators=[('RandomForest', ...  \n",
       "8   (DecisionTreeClassifier(max_depth=13, max_feat...  \n",
       "9   ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "10  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "11  XGBClassifier(base_score=None, booster=None, c...  \n",
       "12  (KNeighborsClassifier(n_neighbors=12, p=1, wei...  \n",
       "13  (LogisticRegression(C=10, penalty='l1', random...  \n",
       "14  StackingClassifier(classifiers=[RandomForestCl...  \n",
       "15  VotingClassifier(estimators=[('RandomForest', ...  \n",
       "16  (DecisionTreeClassifier(max_depth=13, max_feat...  \n",
       "17  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "18  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "19  XGBClassifier(base_score=None, booster=None, c...  \n",
       "20  (KNeighborsClassifier(n_neighbors=12, p=1, wei...  \n",
       "21  (LogisticRegression(C=10, penalty='l1', random...  \n",
       "22  StackingClassifier(classifiers=[RandomForestCl...  \n",
       "23  VotingClassifier(estimators=[('RandomForest', ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "897fbd7b-602a-41ec-86a7-71bb1080be5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Sampling Technique</th>\n",
       "      <th>AUC_train</th>\n",
       "      <th>AUC_test</th>\n",
       "      <th>F1_train</th>\n",
       "      <th>F1_test</th>\n",
       "      <th>Best_threshold</th>\n",
       "      <th>Model_fitted_with_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918013</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.590983</td>\n",
       "      <td>0.3</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=13, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914492</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.578757</td>\n",
       "      <td>0.4</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=13, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.928408</td>\n",
       "      <td>0.995561</td>\n",
       "      <td>0.612535</td>\n",
       "      <td>0.4</td>\n",
       "      <td>StackingClassifier(classifiers=[RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.855160</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(KNeighborsClassifier(n_neighbors=12, p=1, wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.862160</td>\n",
       "      <td>0.998449</td>\n",
       "      <td>0.505082</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(KNeighborsClassifier(n_neighbors=12, p=1, wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN_Bagging</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.831379</td>\n",
       "      <td>0.994577</td>\n",
       "      <td>0.470946</td>\n",
       "      <td>0.6</td>\n",
       "      <td>(KNeighborsClassifier(n_neighbors=12, p=1, wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.999697</td>\n",
       "      <td>0.921392</td>\n",
       "      <td>0.989296</td>\n",
       "      <td>0.597963</td>\n",
       "      <td>0.4</td>\n",
       "      <td>StackingClassifier(classifiers=[RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.925302</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.595976</td>\n",
       "      <td>0.7</td>\n",
       "      <td>StackingClassifier(classifiers=[RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.999181</td>\n",
       "      <td>0.918028</td>\n",
       "      <td>0.985235</td>\n",
       "      <td>0.589729</td>\n",
       "      <td>0.3</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.998858</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.981922</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Voting</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.998497</td>\n",
       "      <td>0.928456</td>\n",
       "      <td>0.969996</td>\n",
       "      <td>0.610740</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VotingClassifier(estimators=[('RandomForest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Voting</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.998132</td>\n",
       "      <td>0.918849</td>\n",
       "      <td>0.971349</td>\n",
       "      <td>0.596018</td>\n",
       "      <td>0.5</td>\n",
       "      <td>VotingClassifier(estimators=[('RandomForest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Voting</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.997532</td>\n",
       "      <td>0.924742</td>\n",
       "      <td>0.968071</td>\n",
       "      <td>0.591293</td>\n",
       "      <td>0.7</td>\n",
       "      <td>VotingClassifier(estimators=[('RandomForest', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.996995</td>\n",
       "      <td>0.923349</td>\n",
       "      <td>0.970666</td>\n",
       "      <td>0.600933</td>\n",
       "      <td>0.3</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.993833</td>\n",
       "      <td>0.921574</td>\n",
       "      <td>0.965605</td>\n",
       "      <td>0.602683</td>\n",
       "      <td>0.5</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.976400</td>\n",
       "      <td>0.914185</td>\n",
       "      <td>0.908689</td>\n",
       "      <td>0.579139</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=13, max_feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.968127</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>0.907336</td>\n",
       "      <td>0.603972</td>\n",
       "      <td>0.7</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.951248</td>\n",
       "      <td>0.922566</td>\n",
       "      <td>0.887981</td>\n",
       "      <td>0.596988</td>\n",
       "      <td>0.7</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.939077</td>\n",
       "      <td>0.885299</td>\n",
       "      <td>0.874056</td>\n",
       "      <td>0.525406</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.916183</td>\n",
       "      <td>0.904841</td>\n",
       "      <td>0.844058</td>\n",
       "      <td>0.539838</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.915242</td>\n",
       "      <td>0.905472</td>\n",
       "      <td>0.840500</td>\n",
       "      <td>0.545320</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.913123</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.849156</td>\n",
       "      <td>0.496129</td>\n",
       "      <td>0.6</td>\n",
       "      <td>(LogisticRegression(C=10, penalty='l1', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.880591</td>\n",
       "      <td>0.867675</td>\n",
       "      <td>0.805260</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(LogisticRegression(C=10, penalty='l1', random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogReg_Bagging</td>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.878122</td>\n",
       "      <td>0.867051</td>\n",
       "      <td>0.806871</td>\n",
       "      <td>0.508148</td>\n",
       "      <td>0.7</td>\n",
       "      <td>(LogisticRegression(C=10, penalty='l1', random...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model    Sampling Technique  AUC_train  AUC_test  F1_train  \\\n",
       "8       RandomForest   Random Oversampling   1.000000  0.918013  0.999983   \n",
       "0       RandomForest                 SMOTE   1.000000  0.914492  0.999216   \n",
       "14          Stacking   Random Oversampling   0.999999  0.928408  0.995561   \n",
       "12       KNN_Bagging   Random Oversampling   0.999998  0.855160  0.998999   \n",
       "4        KNN_Bagging                 SMOTE   0.999993  0.862160  0.998449   \n",
       "20       KNN_Bagging  Random Undersampling   0.999779  0.831379  0.994577   \n",
       "6           Stacking                 SMOTE   0.999697  0.921392  0.989296   \n",
       "22          Stacking  Random Undersampling   0.999225  0.925302  0.981891   \n",
       "1   GradientBoosting                 SMOTE   0.999181  0.918028  0.985235   \n",
       "9   GradientBoosting   Random Oversampling   0.998858  0.922280  0.981922   \n",
       "15            Voting   Random Oversampling   0.998497  0.928456  0.969996   \n",
       "7             Voting                 SMOTE   0.998132  0.918849  0.971349   \n",
       "23            Voting  Random Undersampling   0.997532  0.924742  0.968071   \n",
       "3            XGBoost                 SMOTE   0.996995  0.923349  0.970666   \n",
       "11           XGBoost   Random Oversampling   0.993833  0.921574  0.965605   \n",
       "16      RandomForest  Random Undersampling   0.976400  0.914185  0.908689   \n",
       "17  GradientBoosting  Random Undersampling   0.968127  0.925881  0.907336   \n",
       "19           XGBoost  Random Undersampling   0.951248  0.922566  0.887981   \n",
       "2           AdaBoost                 SMOTE   0.939077  0.885299  0.874056   \n",
       "18          AdaBoost  Random Undersampling   0.916183  0.904841  0.844058   \n",
       "10          AdaBoost   Random Oversampling   0.915242  0.905472  0.840500   \n",
       "5     LogReg_Bagging                 SMOTE   0.913123  0.856743  0.849156   \n",
       "21    LogReg_Bagging  Random Undersampling   0.880591  0.867675  0.805260   \n",
       "13    LogReg_Bagging   Random Oversampling   0.878122  0.867051  0.806871   \n",
       "\n",
       "     F1_test  Best_threshold  \\\n",
       "8   0.590983             0.3   \n",
       "0   0.578757             0.4   \n",
       "14  0.612535             0.4   \n",
       "12  0.494516             0.5   \n",
       "4   0.505082             0.5   \n",
       "20  0.470946             0.6   \n",
       "6   0.597963             0.4   \n",
       "22  0.595976             0.7   \n",
       "1   0.589729             0.3   \n",
       "9   0.600000             0.5   \n",
       "15  0.610740             0.5   \n",
       "7   0.596018             0.5   \n",
       "23  0.591293             0.7   \n",
       "3   0.600933             0.3   \n",
       "11  0.602683             0.5   \n",
       "16  0.579139             0.7   \n",
       "17  0.603972             0.7   \n",
       "19  0.596988             0.7   \n",
       "2   0.525406             0.5   \n",
       "18  0.539838             0.5   \n",
       "10  0.545320             0.5   \n",
       "5   0.496129             0.6   \n",
       "21  0.505618             0.7   \n",
       "13  0.508148             0.7   \n",
       "\n",
       "                          Model_fitted_with_threshold  \n",
       "8   (DecisionTreeClassifier(max_depth=13, max_feat...  \n",
       "0   (DecisionTreeClassifier(max_depth=13, max_feat...  \n",
       "14  StackingClassifier(classifiers=[RandomForestCl...  \n",
       "12  (KNeighborsClassifier(n_neighbors=12, p=1, wei...  \n",
       "4   (KNeighborsClassifier(n_neighbors=12, p=1, wei...  \n",
       "20  (KNeighborsClassifier(n_neighbors=12, p=1, wei...  \n",
       "6   StackingClassifier(classifiers=[RandomForestCl...  \n",
       "22  StackingClassifier(classifiers=[RandomForestCl...  \n",
       "1   ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "9   ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "15  VotingClassifier(estimators=[('RandomForest', ...  \n",
       "7   VotingClassifier(estimators=[('RandomForest', ...  \n",
       "23  VotingClassifier(estimators=[('RandomForest', ...  \n",
       "3   XGBClassifier(base_score=None, booster=None, c...  \n",
       "11  XGBClassifier(base_score=None, booster=None, c...  \n",
       "16  (DecisionTreeClassifier(max_depth=13, max_feat...  \n",
       "17  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "19  XGBClassifier(base_score=None, booster=None, c...  \n",
       "2   (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "18  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "10  (DecisionTreeClassifier(max_depth=1, random_st...  \n",
       "5   (LogisticRegression(C=10, penalty='l1', random...  \n",
       "21  (LogisticRegression(C=10, penalty='l1', random...  \n",
       "13  (LogisticRegression(C=10, penalty='l1', random...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2_sorted = results_df2.sort_values(by='AUC_train', ascending=False)\n",
    "results_df2_sorted # in descending order on the basis of best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ff4f912-66ff-4b9f-8d88-d8ee154015a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                                                                   Stacking\n",
       "Sampling Technique                                           Random Oversampling\n",
       "AUC_train                                                               0.999999\n",
       "AUC_test                                                                0.928408\n",
       "F1_train                                                                0.995561\n",
       "F1_test                                                                 0.612535\n",
       "Best_threshold                                                               0.4\n",
       "Model_fitted_with_threshold    StackingClassifier(classifiers=[RandomForestCl...\n",
       "Name: 14, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2_sorted.loc[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40587f91-8c15-45a1-9841-9a0c529c6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chosen model details is as displayed above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
